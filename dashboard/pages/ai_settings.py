#!/usr/bin/env python3
"""
AIæ¨¡å‹è¨­å®šç”»é¢
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§AIãƒ¢ãƒ‡ãƒ«ã‚’åˆ‡ã‚Šæ›¿ãˆãƒ»ã‚³ã‚¹ãƒˆç›£è¦–
"""

import streamlit as st
import sys
import os
import asyncio
import json
from datetime import datetime, timedelta
import plotly.graph_objects as go
import plotly.express as px
import pandas as pd

# ãƒ‘ã‚¹è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config.ai_models import model_manager, TaskType, AI_MODELS, AIProvider
from config.ai_client import ai_client

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="AIæ¨¡å‹è¨­å®š",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    /* ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰è¨­å®š */
    .stApp {
        background-color: #0e1117;
    }
    
    /* æ¨¡å‹ã‚«ãƒ¼ãƒ‰ */
    .model-card {
        background: linear-gradient(135deg, #1e293b 0%, #334155 100%);
        border: 2px solid #374151;
        border-radius: 12px;
        padding: 20px;
        margin: 10px 0;
        transition: all 0.3s ease;
    }
    
    .model-card:hover {
        border-color: #3b82f6;
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(59, 130, 246, 0.3);
    }
    
    .model-card.selected {
        border-color: #10b981;
        background: linear-gradient(135deg, #065f46 0%, #047857 100%);
    }
    
    .model-name {
        font-size: 1.2rem;
        font-weight: bold;
        color: #3b82f6;
        margin-bottom: 8px;
    }
    
    .model-card.selected .model-name {
        color: #10b981;
    }
    
    .model-specs {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
        gap: 10px;
        margin: 15px 0;
    }
    
    .spec-item {
        background: rgba(30, 41, 59, 0.5);
        padding: 8px 12px;
        border-radius: 6px;
        text-align: center;
    }
    
    .spec-label {
        font-size: 0.8rem;
        color: #94a3b8;
        margin-bottom: 4px;
    }
    
    .spec-value {
        font-weight: bold;
        color: #e2e8f0;
    }
    
    /* ã‚³ã‚¹ãƒˆè¡¨ç¤º */
    .cost-display {
        background: rgba(239, 68, 68, 0.1);
        border: 1px solid rgba(239, 68, 68, 0.3);
        padding: 15px;
        border-radius: 8px;
        text-align: center;
    }
    
    .cost-value {
        font-size: 1.5rem;
        font-weight: bold;
        color: #ef4444;
    }
    
    /* æœ€é©åŒ–ãƒœã‚¿ãƒ³ */
    .optimization-button {
        background: linear-gradient(90deg, #3b82f6 0%, #10b981 100%);
        color: white;
        padding: 12px 24px;
        border-radius: 25px;
        border: none;
        font-weight: bold;
        cursor: pointer;
        transition: all 0.3s;
    }
    
    .optimization-button:hover {
        transform: scale(1.05);
        box-shadow: 0 5px 15px rgba(59, 130, 246, 0.4);
    }
    
    /* çµ±è¨ˆã‚°ãƒªãƒƒãƒ‰ */
    .stats-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 20px;
        margin: 20px 0;
    }
    
    .stat-card {
        background: linear-gradient(135deg, #1e293b 0%, #334155 100%);
        padding: 20px;
        border-radius: 12px;
        text-align: center;
    }
    
    .stat-value {
        font-size: 2rem;
        font-weight: bold;
        color: #3b82f6;
        margin: 10px 0;
    }
    
    .stat-label {
        color: #94a3b8;
        font-size: 0.9rem;
    }
</style>
""", unsafe_allow_html=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
if 'ai_test_results' not in st.session_state:
    st.session_state.ai_test_results = []

# ãƒ˜ãƒƒãƒ€ãƒ¼
st.title("ğŸ¤– AIæ¨¡å‹è¨­å®šãƒ»ç›£è¦–ã‚»ãƒ³ã‚¿ãƒ¼")
st.caption("ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã®AIä½¿ç”¨é‡ã¨ã‚³ã‚¹ãƒˆã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç®¡ç†")

# ã‚¿ãƒ–æ§‹æˆ
tabs = st.tabs(["âš™ï¸ æ¨¡å‹è¨­å®š", "ğŸ“Š ä½¿ç”¨çµ±è¨ˆ", "ğŸ’° ã‚³ã‚¹ãƒˆåˆ†æ", "ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"])

# ã‚¿ãƒ–1: æ¨¡å‹è¨­å®š
with tabs[0]:
    st.header("ğŸ¯ ç”¨é€”åˆ¥AIæ¨¡å‹è¨­å®š")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ç¾åœ¨ã®è¨­å®š")
        
        # å„ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã®è¨­å®š
        for task_type in TaskType:
            current_model = model_manager.get_current_config()[task_type]
            if current_model is None:
                st.warning(f"{task_type.value}: åˆ©ç”¨å¯èƒ½ãªAIãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                continue
            current_config = AI_MODELS[current_model]
            
            with st.expander(f"{task_type.value.replace('_', ' ').title()}", expanded=True):
                col_model, col_change = st.columns([3, 1])
                
                with col_model:
                    # ç¾åœ¨ã®æ¨¡å‹æƒ…å ±è¡¨ç¤º
                    st.markdown(f"""
                    <div class="model-card selected">
                        <div class="model-name">{current_model}</div>
                        <div class="model-specs">
                            <div class="spec-item">
                                <div class="spec-label">ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼</div>
                                <div class="spec-value">{current_config.provider.value}</div>
                            </div>
                            <div class="spec-item">
                                <div class="spec-label">ã‚³ã‚¹ãƒˆ/1K tokens</div>
                                <div class="spec-value">Â¥{current_config.cost_per_1k_tokens:.4f}</div>
                            </div>
                            <div class="spec-item">
                                <div class="spec-label">æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³</div>
                                <div class="spec-value">{current_config.max_tokens:,}</div>
                            </div>
                        </div>
                        <p style="color: #94a3b8; font-size: 0.9rem;">{current_config.description}</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col_change:
                    # æ¨¡å‹å¤‰æ›´
                    new_model = st.selectbox(
                        "æ¨¡å‹ã‚’å¤‰æ›´",
                        options=list(AI_MODELS.keys()),
                        index=list(AI_MODELS.keys()).index(current_model),
                        key=f"model_select_{task_type.value}"
                    )
                    
                    if new_model != current_model:
                        if st.button(f"å¤‰æ›´", key=f"change_{task_type.value}"):
                            model_manager.set_model_for_task(task_type, new_model)
                            st.success(f"âœ… {task_type.value}ã®æ¨¡å‹ã‚’{new_model}ã«å¤‰æ›´ã—ã¾ã—ãŸ")
                            st.rerun()
    
    with col2:
        st.subheader("ã‚¯ã‚¤ãƒƒã‚¯æœ€é©åŒ–")
        
        # æœ€é©åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        if st.button("ğŸ’° ã‚³ã‚¹ãƒˆæœ€é©åŒ–", help="å…¨ã‚¿ã‚¹ã‚¯ã‚’æœ€å®‰æ¨¡å‹ã«è¨­å®š"):
            model_manager.optimize_for_cost()
            st.success("ã‚³ã‚¹ãƒˆæœ€é©åŒ–è¨­å®šã‚’é©ç”¨ã—ã¾ã—ãŸ")
            st.rerun()
        
        if st.button("âœ¨ å“è³ªæœ€é©åŒ–", help="å…¨ã‚¿ã‚¹ã‚¯ã‚’æœ€é«˜å“è³ªæ¨¡å‹ã«è¨­å®š"):
            model_manager.optimize_for_quality()
            st.success("å“è³ªæœ€é©åŒ–è¨­å®šã‚’é©ç”¨ã—ã¾ã—ãŸ")
            st.rerun()
        
        if st.button("âš–ï¸ ãƒãƒ©ãƒ³ã‚¹è¨­å®š", help="æ¨å¥¨ãƒãƒ©ãƒ³ã‚¹è¨­å®šã«æˆ»ã™"):
            from config.ai_models import TASK_MODEL_MAPPING
            for task_type, model_name in TASK_MODEL_MAPPING.items():
                model_manager.set_model_for_task(task_type, model_name)
            st.success("æ¨å¥¨ãƒãƒ©ãƒ³ã‚¹è¨­å®šã‚’é©ç”¨ã—ã¾ã—ãŸ")
            st.rerun()
        
        # ç¾åœ¨ã®è¨­å®šã§ã®ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š
        st.subheader("ğŸ“ˆ ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š")
        
        st.write("**1å›ã®å®Ÿè¡Œã‚ãŸã‚Šï¼ˆ1000 input + 500 output tokensï¼‰:**")
        
        total_cost = 0
        for task_type in TaskType:
            cost = model_manager.get_cost_estimate(task_type, 1000, 500)
            total_cost += cost
            st.metric(
                task_type.value.replace('_', ' ').title(),
                f"Â¥{cost:.4f}"
            )
        
        st.markdown(f"""
        <div class="cost-display">
            <div style="color: #94a3b8;">ç·ã‚³ã‚¹ãƒˆ</div>
            <div class="cost-value">Â¥{total_cost:.4f}</div>
        </div>
        """, unsafe_allow_html=True)

# ã‚¿ãƒ–2: ä½¿ç”¨çµ±è¨ˆ
with tabs[1]:
    st.header("ğŸ“Š AIä½¿ç”¨çµ±è¨ˆ")
    
    # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿å–å¾—
    usage_stats = ai_client.get_usage_stats()
    
    # çµ±è¨ˆè¡¨ç¤º
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="stat-card">
            <div class="stat-value">{usage_stats['requests']}</div>
            <div class="stat-label">ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="stat-card">
            <div class="stat-value">Â¥{usage_stats['total_cost']:.2f}</div>
            <div class="stat-label">ç·ã‚³ã‚¹ãƒˆ</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="stat-card">
            <div class="stat-value">{usage_stats['total_tokens']:,}</div>
            <div class="stat-label">ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        avg_cost = usage_stats['total_cost'] / max(usage_stats['requests'], 1)
        st.markdown(f"""
        <div class="stat-card">
            <div class="stat-value">Â¥{avg_cost:.4f}</div>
            <div class="stat-label">å¹³å‡ã‚³ã‚¹ãƒˆ/ãƒªã‚¯ã‚¨ã‚¹ãƒˆ</div>
        </div>
        """, unsafe_allow_html=True)
    
    # æ¨¡å‹åˆ¥ä½¿ç”¨é‡ã‚°ãƒ©ãƒ•
    if usage_stats['model_usage']:
        st.subheader("æ¨¡å‹åˆ¥ä½¿ç”¨é‡")
        
        model_data = []
        for model, stats in usage_stats['model_usage'].items():
            model_data.append({
                "æ¨¡å‹": model,
                "ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°": stats['requests'],
                "ã‚³ã‚¹ãƒˆ": stats['cost'],
                "ãƒˆãƒ¼ã‚¯ãƒ³æ•°": stats['tokens']
            })
        
        df = pd.DataFrame(model_data)
        
        # å††ã‚°ãƒ©ãƒ•
        col1, col2 = st.columns(2)
        
        with col1:
            fig_requests = px.pie(
                df, 
                values='ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°', 
                names='æ¨¡å‹',
                title="ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°åˆ†å¸ƒ",
                color_discrete_sequence=['#3b82f6', '#10b981', '#f59e0b', '#8b5cf6']
            )
            fig_requests.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font=dict(color='white')
            )
            st.plotly_chart(fig_requests, use_container_width=True)
        
        with col2:
            fig_cost = px.pie(
                df, 
                values='ã‚³ã‚¹ãƒˆ', 
                names='æ¨¡å‹',
                title="ã‚³ã‚¹ãƒˆåˆ†å¸ƒ",
                color_discrete_sequence=['#ef4444', '#f59e0b', '#10b981', '#3b82f6']
            )
            fig_cost.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font=dict(color='white')
            )
            st.plotly_chart(fig_cost, use_container_width=True)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        st.subheader("è©³ç´°ãƒ‡ãƒ¼ã‚¿")
        st.dataframe(df, use_container_width=True)
    else:
        st.info("ã¾ã ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

# ã‚¿ãƒ–3: ã‚³ã‚¹ãƒˆåˆ†æ
with tabs[2]:
    st.header("ğŸ’° ã‚³ã‚¹ãƒˆåˆ†æãƒ»äºˆæ¸¬")
    
    # æœˆé–“ä½¿ç”¨é‡äºˆæ¸¬
    st.subheader("ğŸ“ˆ æœˆé–“ã‚³ã‚¹ãƒˆäºˆæ¸¬")
    
    # äºˆæ¸¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    col1, col2 = st.columns(2)
    
    with col1:
        daily_requests = st.number_input("1æ—¥ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°", min_value=1, value=100, step=10)
        avg_input_tokens = st.number_input("å¹³å‡å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°", min_value=100, value=1000, step=100)
        avg_output_tokens = st.number_input("å¹³å‡å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°", min_value=50, value=500, step=50)
    
    with col2:
        # å„ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã®ä½¿ç”¨é »åº¦
        st.write("**ã‚¿ã‚¹ã‚¯åˆ¥ä½¿ç”¨æ¯”ç‡ (%)**")
        task_ratios = {}
        total_ratio = 0
        
        for task_type in TaskType:
            ratio = st.slider(
                task_type.value.replace('_', ' ').title(),
                0, 100, 
                value=100 // len(TaskType),
                key=f"ratio_{task_type.value}"
            )
            task_ratios[task_type] = ratio
            total_ratio += ratio
        
        if total_ratio > 100:
            st.warning(f"åˆè¨ˆãŒ100%ã‚’è¶…ãˆã¦ã„ã¾ã™ ({total_ratio}%)")
    
    # ã‚³ã‚¹ãƒˆè¨ˆç®—
    if st.button("ğŸ’° ã‚³ã‚¹ãƒˆäºˆæ¸¬ã‚’å®Ÿè¡Œ"):
        monthly_costs = {}
        total_monthly_cost = 0
        
        for task_type, ratio in task_ratios.items():
            if ratio > 0:
                daily_task_requests = daily_requests * (ratio / 100)
                daily_cost = model_manager.get_cost_estimate(
                    task_type, avg_input_tokens, avg_output_tokens
                ) * daily_task_requests
                monthly_cost = daily_cost * 30
                monthly_costs[task_type.value] = monthly_cost
                total_monthly_cost += monthly_cost
        
        # çµæœè¡¨ç¤º
        st.subheader("ğŸ“Š äºˆæ¸¬çµæœ")
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.markdown(f"""
            <div class="cost-display">
                <div style="color: #94a3b8;">æœˆé–“ç·ã‚³ã‚¹ãƒˆ</div>
                <div class="cost-value">Â¥{total_monthly_cost:.2f}</div>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown(f"""
            <div style="background: rgba(16, 185, 129, 0.1); padding: 15px; border-radius: 8px; text-align: center; margin-top: 20px;">
                <div style="color: #94a3b8;">å¹´é–“äºˆæ¸¬ã‚³ã‚¹ãƒˆ</div>
                <div style="font-size: 1.3rem; font-weight: bold; color: #10b981;">Â¥{total_monthly_cost * 12:.2f}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            if monthly_costs:
                # ã‚¿ã‚¹ã‚¯åˆ¥ã‚³ã‚¹ãƒˆã‚°ãƒ©ãƒ•
                fig = go.Figure(data=[
                    go.Bar(
                        x=list(monthly_costs.keys()),
                        y=list(monthly_costs.values()),
                        marker_color=['#3b82f6', '#10b981', '#f59e0b', '#8b5cf6', '#ef4444', '#06b6d4']
                    )
                ])
                
                fig.update_layout(
                    title="ã‚¿ã‚¹ã‚¯åˆ¥æœˆé–“ã‚³ã‚¹ãƒˆ",
                    xaxis_title="ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—",
                    yaxis_title="ã‚³ã‚¹ãƒˆ (Â¥)",
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)',
                    font=dict(color='white')
                )
                
                st.plotly_chart(fig, use_container_width=True)

# ã‚¿ãƒ–4: ãƒ†ã‚¹ãƒˆãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
with tabs[3]:
    st.header("ğŸ§ª AIæ¨¡å‹ãƒ†ã‚¹ãƒˆãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    st.subheader("âš¡ ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        test_prompt = st.text_area(
            "ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            value="AIãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã®åˆ©ç‚¹ã‚’3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚",
            height=100
        )
        
        test_task_type = st.selectbox(
            "ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—",
            options=list(TaskType),
            format_func=lambda x: x.value.replace('_', ' ').title()
        )
    
    with col2:
        if st.button("ğŸš€ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ", type="primary"):
            with st.spinner("AIæ¨¡å‹ã‚’ãƒ†ã‚¹ãƒˆä¸­..."):
                try:
                    # éåŒæœŸå‡¦ç†ã®ãŸã‚ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—å‡¦ç†
                    import asyncio
                    
                    async def run_test():
                        return await ai_client.generate_content(test_prompt, test_task_type)
                    
                    # æ—¢å­˜ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ãŒã‚ã‚‹å ´åˆã®å‡¦ç†
                    try:
                        loop = asyncio.get_event_loop()
                        if loop.is_running():
                            # Streamlitã®ç’°å¢ƒã§ã¯æ–°ã—ã„ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
                            import concurrent.futures
                            with concurrent.futures.ThreadPoolExecutor() as executor:
                                future = executor.submit(asyncio.run, run_test())
                                response = future.result(timeout=30)
                        else:
                            response = loop.run_until_complete(run_test())
                    except RuntimeError:
                        response = asyncio.run(run_test())
                    
                    # çµæœã‚’ä¿å­˜
                    test_result = {
                        "timestamp": datetime.now(),
                        "prompt": test_prompt,
                        "task_type": test_task_type.value,
                        "response": response.to_dict()
                    }
                    st.session_state.ai_test_results.append(test_result)
                    
                    # çµæœè¡¨ç¤º
                    st.success("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
                    
                    with st.expander("ğŸ“‹ ãƒ†ã‚¹ãƒˆçµæœ", expanded=True):
                        st.write(f"**ä½¿ç”¨æ¨¡å‹:** {response.model}")
                        st.write(f"**ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼:** {response.provider}")
                        st.write(f"**ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“:** {response.response_time:.2f}ç§’")
                        st.write(f"**ä½¿ç”¨ãƒˆãƒ¼ã‚¯ãƒ³:** {response.tokens_used}")
                        st.write(f"**ã‚³ã‚¹ãƒˆ:** Â¥{response.cost:.4f}")
                        
                        st.markdown("**ç”Ÿæˆå†…å®¹:**")
                        st.info(response.content)
                
                except Exception as e:
                    st.error(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãƒ†ã‚¹ãƒˆå±¥æ­´
    if st.session_state.ai_test_results:
        st.subheader("ğŸ“œ ãƒ†ã‚¹ãƒˆå±¥æ­´")
        
        # æœ€æ–°5ä»¶ã®ãƒ†ã‚¹ãƒˆçµæœã‚’è¡¨ç¤º
        recent_tests = st.session_state.ai_test_results[-5:]
        
        for i, test_result in enumerate(reversed(recent_tests)):
            with st.expander(f"ãƒ†ã‚¹ãƒˆ {len(recent_tests)-i}: {test_result['timestamp'].strftime('%H:%M:%S')} - {test_result['task_type']}", expanded=False):
                col1, col2 = st.columns([1, 1])
                
                with col1:
                    st.write(f"**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:** {test_result['prompt'][:100]}...")
                    st.write(f"**æ¨¡å‹:** {test_result['response']['model']}")
                    st.write(f"**ã‚³ã‚¹ãƒˆ:** Â¥{test_result['response']['cost']:.4f}")
                
                with col2:
                    st.write(f"**ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“:** {test_result['response']['response_time']:.2f}ç§’")
                    st.write(f"**ãƒˆãƒ¼ã‚¯ãƒ³æ•°:** {test_result['response']['tokens_used']}")
                
                st.markdown("**å¿œç­”å†…å®¹:**")
                st.code(test_result['response']['content'][:200] + "..." if len(test_result['response']['content']) > 200 else test_result['response']['content'])
        
        # å±¥æ­´ã‚¯ãƒªã‚¢
        if st.button("ğŸ—‘ï¸ ãƒ†ã‚¹ãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
            st.session_state.ai_test_results = []
            st.success("å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
            st.rerun()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("ğŸ›ï¸ ã‚·ã‚¹ãƒ†ãƒ åˆ¶å¾¡")
    
    # çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ
    if st.button("ğŸ”„ ä½¿ç”¨çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ", type="secondary"):
        ai_client.reset_stats()
        st.success("çµ±è¨ˆã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
        st.rerun()
    
    # è¨­å®šã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    if st.button("ğŸ“¥ è¨­å®šã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
        config_data = {
            "model_config": model_manager.get_current_config(),
            "usage_stats": ai_client.get_usage_stats(),
            "export_time": datetime.now().isoformat()
        }
        
        st.download_button(
            label="ğŸ’¾ JSON ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=json.dumps({k: str(v) if not isinstance(v, (dict, list)) else v for k, v in config_data.items()}, 
                          ensure_ascii=False, indent=2),
            file_name=f"ai_config_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
    
    st.markdown("---")
    
    st.header("ğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–")
    
    # ç¾åœ¨ã®è¨­å®šã‚µãƒãƒªãƒ¼
    current_config = model_manager.get_current_config()
    
    for task_type, model_name in current_config.items():
        if model_name is None:
            st.metric(
                task_type.value.replace('_', ' ').title(),
                "Not Available",
                "No API Key"
            )
        else:
            config = AI_MODELS[model_name]
            st.metric(
                task_type.value.replace('_', ' ').title(),
                model_name,
                f"Â¥{config.cost_per_1k_tokens:.4f}/1K"
            )
    
    st.markdown("---")
    
    # ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹
    st.header("ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹")
    
    if st.button("ğŸ  ãƒ›ãƒ¼ãƒ ã«æˆ»ã‚‹", use_container_width=True):
        st.switch_page("pages/../home.py")
    
    if st.button("ğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†å®¤", use_container_width=True):
        st.switch_page("pages/project_management.py")