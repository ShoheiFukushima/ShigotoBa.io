#!/usr/bin/env python3
"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½
ä½ã‚³ã‚¹ãƒˆAIãƒ¢ãƒ‡ãƒ«ï¼ˆGemini Flashï¼‰ã§ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ”¯æ´
"""

import streamlit as st
import sys
import os
import asyncio
import json
from datetime import datetime
import uuid

# ãƒ‘ã‚¹è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config.ai_models import TaskType
from config.ai_client import ai_client

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒƒãƒˆ",
    page_icon="ğŸ’¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    /* ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰è¨­å®š */
    .stApp {
        background-color: #0e1117;
    }
    
    /* ãƒãƒ£ãƒƒãƒˆã‚³ãƒ³ãƒ†ãƒŠ */
    .chat-container {
        height: 500px;
        overflow-y: auto;
        padding: 20px;
        background: rgba(30, 41, 59, 0.3);
        border-radius: 15px;
        border: 1px solid rgba(59, 130, 246, 0.2);
        margin-bottom: 20px;
    }
    
    .chat-container::-webkit-scrollbar {
        width: 8px;
    }
    
    .chat-container::-webkit-scrollbar-track {
        background: rgba(30, 41, 59, 0.3);
    }
    
    .chat-container::-webkit-scrollbar-thumb {
        background: #3b82f6;
        border-radius: 4px;
    }
    
    /* ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */
    .user-message {
        background: linear-gradient(135deg, #3b82f6 0%, #1d4ed8 100%);
        color: white;
        padding: 15px 20px;
        border-radius: 20px 20px 5px 20px;
        margin: 10px 0 10px 60px;
        box-shadow: 0 2px 10px rgba(59, 130, 246, 0.3);
        position: relative;
    }
    
    .user-message::before {
        content: "ğŸ‘¤";
        position: absolute;
        left: -50px;
        top: 15px;
        font-size: 1.5rem;
    }
    
    /* AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */
    .ai-message {
        background: linear-gradient(135deg, #10b981 0%, #059669 100%);
        color: white;
        padding: 15px 20px;
        border-radius: 20px 20px 20px 5px;
        margin: 10px 60px 10px 0;
        box-shadow: 0 2px 10px rgba(16, 185, 129, 0.3);
        position: relative;
    }
    
    .ai-message::after {
        content: "ğŸ¤–";
        position: absolute;
        right: -50px;
        top: 15px;
        font-size: 1.5rem;
    }
    
    /* ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */
    .system-message {
        background: rgba(107, 114, 128, 0.2);
        color: #9ca3af;
        padding: 10px 15px;
        border-radius: 10px;
        margin: 5px 20px;
        text-align: center;
        font-size: 0.9rem;
        border: 1px solid rgba(107, 114, 128, 0.3);
    }
    
    /* å…¥åŠ›ã‚¨ãƒªã‚¢ */
    .chat-input-container {
        background: rgba(30, 41, 59, 0.8);
        padding: 20px;
        border-radius: 15px;
        border: 1px solid rgba(59, 130, 246, 0.2);
    }
    
    /* ãƒ—ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ */
    .preset-button {
        background: rgba(59, 130, 246, 0.1);
        border: 1px solid rgba(59, 130, 246, 0.3);
        color: #3b82f6;
        padding: 8px 16px;
        border-radius: 20px;
        margin: 5px;
        cursor: pointer;
        transition: all 0.3s;
        display: inline-block;
        font-size: 0.9rem;
    }
    
    .preset-button:hover {
        background: rgba(59, 130, 246, 0.2);
        transform: translateY(-2px);
    }
    
    /* ã‚³ã‚¹ãƒˆè¡¨ç¤º */
    .cost-indicator {
        position: fixed;
        top: 80px;
        right: 20px;
        background: rgba(30, 41, 59, 0.9);
        padding: 10px 15px;
        border-radius: 10px;
        border: 1px solid rgba(16, 185, 129, 0.3);
        font-size: 0.8rem;
        z-index: 30;
    }
    
    .cost-value {
        color: #10b981;
        font-weight: bold;
    }
    
    /* ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ */
    .typing-indicator {
        background: rgba(107, 114, 128, 0.2);
        padding: 15px 20px;
        border-radius: 20px 20px 20px 5px;
        margin: 10px 60px 10px 0;
        position: relative;
    }
    
    .typing-dots {
        display: inline-block;
    }
    
    .typing-dots span {
        display: inline-block;
        width: 8px;
        height: 8px;
        border-radius: 50%;
        background-color: #9ca3af;
        margin: 0 2px;
        animation: typing 1.4s infinite both;
    }
    
    .typing-dots span:nth-child(2) {
        animation-delay: 0.2s;
    }
    
    .typing-dots span:nth-child(3) {
        animation-delay: 0.4s;
    }
    
    @keyframes typing {
        0%, 60%, 100% {
            transform: translateY(0);
            opacity: 0.4;
        }
        30% {
            transform: translateY(-10px);
            opacity: 1;
        }
    }
    
    /* ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ¡ã‚¿æƒ…å ± */
    .message-meta {
        font-size: 0.7rem;
        opacity: 0.7;
        margin-top: 5px;
    }
</style>
""", unsafe_allow_html=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'chat_session_id' not in st.session_state:
    st.session_state.chat_session_id = str(uuid.uuid4())
if 'total_chat_cost' not in st.session_state:
    st.session_state.total_chat_cost = 0.0
if 'is_typing' not in st.session_state:
    st.session_state.is_typing = False

# ãƒ—ãƒªã‚»ãƒƒãƒˆè³ªå•
PRESET_QUESTIONS = [
    "ã“ã®ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã®ç«¶åˆã¯ã©ã“ã§ã™ã‹ï¼Ÿ",
    "SNSæŠ•ç¨¿ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’5ã¤æ•™ãˆã¦",
    "ä¾¡æ ¼è¨­å®šã®æˆ¦ç•¥ã‚’ææ¡ˆã—ã¦",
    "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã®åˆ†æã‚’ãŠé¡˜ã„ã—ã¾ã™",
    "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°äºˆç®—ã®é…åˆ†æ–¹æ³•ã¯ï¼Ÿ",
    "ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ã®æ›¸ãæ–¹ã‚’æ•™ãˆã¦",
    "ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®KPIè¨­å®šã«ã¤ã„ã¦",
    "ãƒ–ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹"
]

# ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°å°‚ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
MARKETING_SYSTEM_PROMPT = """
ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚

å°‚é–€åˆ†é‡ï¼š
- ãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥
- ãƒ–ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°
- SNSãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°
- ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°
- ç«¶åˆåˆ†æ
- ä¾¡æ ¼æˆ¦ç•¥
- ROIåˆ†æ

å›ç­”ã‚¹ã‚¿ã‚¤ãƒ«ï¼š
- ç°¡æ½”ã§å®Ÿç”¨çš„
- å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³å«ã‚€
- æ•°å­—ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚’é‡è¦–
- æ—¥æœ¬å¸‚å ´ã«æœ€é©åŒ–
- ã‚³ã‚¹ãƒˆåŠ¹ç‡ã‚’é‡è¦–

åˆ¶ç´„ï¼š
- 200æ–‡å­—ä»¥å†…ã§è¦ç‚¹ã‚’ã¾ã¨ã‚ã‚‹
- å¿…è¦ã«å¿œã˜ã¦ç®‡æ¡æ›¸ãä½¿ç”¨
- å°‚é–€ç”¨èªã¯åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜
"""

def add_message(role: str, content: str, metadata: dict = None):
    """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ """
    message = {
        "id": str(uuid.uuid4()),
        "role": role,
        "content": content,
        "timestamp": datetime.now(),
        "metadata": metadata or {}
    }
    st.session_state.chat_history.append(message)

def render_message(message: dict):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""
    timestamp = message["timestamp"].strftime("%H:%M:%S")
    
    if message["role"] == "user":
        st.markdown(f"""
        <div class="user-message">
            {message["content"]}
            <div class="message-meta">ğŸ‘¤ {timestamp}</div>
        </div>
        """, unsafe_allow_html=True)
    
    elif message["role"] == "assistant":
        cost = message["metadata"].get("cost", 0)
        model = message["metadata"].get("model", "AI")
        tokens = message["metadata"].get("tokens", 0)
        
        st.markdown(f"""
        <div class="ai-message">
            {message["content"]}
            <div class="message-meta">
                ğŸ¤– {model} | {timestamp} | Â¥{cost:.4f} | {tokens} tokens
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    elif message["role"] == "system":
        st.markdown(f"""
        <div class="system-message">
            {message["content"]} - {timestamp}
        </div>
        """, unsafe_allow_html=True)

async def get_ai_response(user_message: str) -> dict:
    """AIå¿œç­”ã‚’å–å¾—ï¼ˆä½ã‚³ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ï¼‰"""
    try:
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ 
        context = ""
        if 'current_project_id' in st.session_state and st.session_state.current_project_id:
            project = st.session_state.projects.get(st.session_state.current_project_id, {})
            if project:
                product_info = project.get('flow_data', {}).get('product', {})
                if product_info:
                    context = f"""
                    
                    ç¾åœ¨ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ï¼š
                    - è£½å“å: {product_info.get('name', 'N/A')}
                    - ã‚«ãƒ†ã‚´ãƒª: {product_info.get('category', 'N/A')}
                    - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {product_info.get('target', 'N/A')}
                    - ä¾¡æ ¼: {product_info.get('price', 'N/A')}
                    - ç‹¬è‡ªä¾¡å€¤: {product_info.get('unique_value', 'N/A')}
                    """
        
        enhanced_prompt = f"{user_message}{context}"
        
        # Chatç”¨ã®ä½ã‚³ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ï¼ˆGemini Flashï¼‰ã§å¿œç­”ç”Ÿæˆ
        response = await ai_client.generate_content(
            prompt=enhanced_prompt,
            task_type=TaskType.CHAT,
            system_prompt=MARKETING_SYSTEM_PROMPT,
            temperature=0.7,
            max_tokens=300  # çŸ­ã„å¿œç­”ã§ã‚³ã‚¹ãƒˆå‰Šæ¸›
        )
        
        return {
            "content": response.content,
            "cost": response.cost,
            "model": response.model,
            "tokens": response.tokens_used
        }
        
    except Exception as e:
        return {
            "content": f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
            "cost": 0,
            "model": "error",
            "tokens": 0
        }

# ãƒ˜ãƒƒãƒ€ãƒ¼
col1, col2 = st.columns([3, 1])

with col1:
    st.title("ğŸ’¬ ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°AIãƒãƒ£ãƒƒãƒˆ")
    st.caption("ä½ã‚³ã‚¹ãƒˆAIï¼ˆGemini Flashï¼‰ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›¸è«‡")

with col2:
    # ã‚³ã‚¹ãƒˆè¡¨ç¤º
    st.markdown(f"""
    <div class="cost-indicator">
        <div>ä»Šã‚»ãƒƒã‚·ãƒ§ãƒ³: <span class="cost-value">Â¥{st.session_state.total_chat_cost:.4f}</span></div>
        <div>ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: <span class="cost-value">Gemini Flash</span></div>
    </div>
    """, unsafe_allow_html=True)

# ãƒãƒ£ãƒƒãƒˆè¡¨ç¤ºã‚¨ãƒªã‚¢
st.markdown('<div class="chat-container">', unsafe_allow_html=True)

# åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
if not st.session_state.chat_history:
    add_message("system", "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒèµ·å‹•ã—ã¾ã—ãŸ")

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
for message in st.session_state.chat_history:
    render_message(message)

# ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ï¼ˆAIå¿œç­”ç”Ÿæˆå¾Œã¯è‡ªå‹•çš„ã«falseã«ãªã‚‹ï¼‰
if st.session_state.get('is_typing', False) and len(st.session_state.chat_history) > 0:
    # æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å ´åˆã®ã¿è¡¨ç¤º
    if st.session_state.chat_history[-1]["role"] == "user":
        st.markdown("""
        <div class="typing-indicator">
            AIãŒå…¥åŠ›ä¸­
            <div class="typing-dots">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        """, unsafe_allow_html=True)

st.markdown('</div>', unsafe_allow_html=True)

# å…¥åŠ›ã‚¨ãƒªã‚¢
st.markdown('<div class="chat-input-container">', unsafe_allow_html=True)

# ãƒ—ãƒªã‚»ãƒƒãƒˆè³ªå•ãƒœã‚¿ãƒ³
st.markdown("**ğŸ’¡ ã‚ˆãã‚ã‚‹è³ªå•:**")
preset_cols = st.columns(4)

for i, question in enumerate(PRESET_QUESTIONS):
    col_index = i % 4
    with preset_cols[col_index]:
        if st.button(question, key=f"preset_{i}", help="ã‚¯ãƒªãƒƒã‚¯ã§è³ªå•ã‚’é€ä¿¡"):
            # ãƒ—ãƒªã‚»ãƒƒãƒˆè³ªå•ã‚’é€ä¿¡ã—ã¦å‡¦ç†
            add_message("user", question)
            st.session_state.is_typing = True
            
            # AIå¿œç­”ã‚’ç”Ÿæˆ
            try:
                import concurrent.futures
                
                async def get_response():
                    return await get_ai_response(question)
                
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, get_response())
                    ai_response = future.result(timeout=30)
                
                # AIå¿œç­”ã‚’è¿½åŠ 
                add_message("assistant", ai_response["content"], {
                    "cost": ai_response["cost"],
                    "model": ai_response["model"],
                    "tokens": ai_response["tokens"]
                })
                
                # ã‚³ã‚¹ãƒˆç´¯è¨ˆæ›´æ–°
                st.session_state.total_chat_cost += ai_response["cost"]
                st.session_state.is_typing = False
                
            except Exception as e:
                add_message("system", f"ã‚¨ãƒ©ãƒ¼: AIå¿œç­”ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ - {str(e)}")
                st.session_state.is_typing = False
            
            st.rerun()

st.markdown("---")

# ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
col1, col2 = st.columns([4, 1])

with col1:
    user_input = st.text_input(
        "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...",
        key="chat_input",
        placeholder="ä¾‹ï¼šã“ã®ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã®ç«¶åˆåˆ†æã‚’ãŠé¡˜ã„ã—ã¾ã™",
        autocomplete="off"
    )

with col2:
    send_button = st.button("ğŸ“¤ é€ä¿¡", type="primary", use_container_width=True)

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡å‡¦ç†
if (send_button or user_input) and user_input.strip():
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
    add_message("user", user_input.strip())
    st.session_state.is_typing = True
    
    # AIå¿œç­”ã‚’ç”Ÿæˆï¼ˆéåŒæœŸå‡¦ç†ï¼‰
    try:
        # Streamlitç’°å¢ƒã§ã®éåŒæœŸå‡¦ç†
        import concurrent.futures
        
        async def get_response():
            return await get_ai_response(user_input.strip())
        
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future = executor.submit(asyncio.run, get_response())
            ai_response = future.result(timeout=30)
        
        # AIå¿œç­”ã‚’è¿½åŠ 
        add_message("assistant", ai_response["content"], {
            "cost": ai_response["cost"],
            "model": ai_response["model"],
            "tokens": ai_response["tokens"]
        })
        
        # ã‚³ã‚¹ãƒˆç´¯è¨ˆæ›´æ–°
        st.session_state.total_chat_cost += ai_response["cost"]
        st.session_state.is_typing = False
        
        # å…¥åŠ›ã‚’ã‚¯ãƒªã‚¢ï¼ˆsession_stateã‚’ç›´æ¥å¤‰æ›´ã—ãªã„ï¼‰
        st.rerun()
        
    except Exception as e:
        add_message("system", f"ã‚¨ãƒ©ãƒ¼: AIå¿œç­”ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ - {str(e)}")
        st.session_state.is_typing = False
        st.rerun()

st.markdown('</div>', unsafe_allow_html=True)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆè¨­å®š")
    
    # ãƒãƒ£ãƒƒãƒˆçµ±è¨ˆ
    st.subheader("ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ")
    st.metric("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°", len([m for m in st.session_state.chat_history if m["role"] != "system"]))
    st.metric("ç·ã‚³ã‚¹ãƒˆ", f"Â¥{st.session_state.total_chat_cost:.4f}")
    
    avg_cost = st.session_state.total_chat_cost / max(len([m for m in st.session_state.chat_history if m["role"] == "assistant"]), 1)
    st.metric("å¹³å‡ã‚³ã‚¹ãƒˆ/è¿”ç­”", f"Â¥{avg_cost:.4f}")
    
    st.markdown("---")
    
    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    st.subheader("ğŸ¤– AIè¨­å®š")
    st.info("**ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«**: Gemini 1.5 Flash")
    st.info("**ã‚³ã‚¹ãƒˆ**: Â¥0.000075/1K tokens")
    st.info("**ç‰¹å¾´**: é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆ")
    
    # ç¾åœ¨ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
    if 'current_project_id' in st.session_state and st.session_state.current_project_id:
        st.subheader("ğŸ“‚ ç¾åœ¨ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ")
        project = st.session_state.projects.get(st.session_state.current_project_id, {})
        if project:
            st.success(f"**{project['name']}**")
            st.caption("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‚’è€ƒæ…®ã—ãŸå›ç­”ã‚’æä¾›ã—ã¾ã™")
        else:
            st.info("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    else:
        st.warning("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    st.markdown("---")
    
    # ãƒãƒ£ãƒƒãƒˆç®¡ç†
    st.subheader("ğŸ—‚ï¸ ãƒãƒ£ãƒƒãƒˆç®¡ç†")
    
    if st.button("ğŸ†• æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ", use_container_width=True):
        st.session_state.chat_history = []
        st.session_state.chat_session_id = str(uuid.uuid4())
        st.session_state.total_chat_cost = 0.0
        st.session_state.is_typing = False
        add_message("system", "æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
        st.success("æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’é–‹å§‹ã—ã¾ã—ãŸ")
        st.rerun()
    
    if st.button("ğŸ“¥ ãƒãƒ£ãƒƒãƒˆå±¥æ­´å‡ºåŠ›", use_container_width=True):
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’JSONå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        chat_export = {
            "session_id": st.session_state.chat_session_id,
            "total_cost": st.session_state.total_chat_cost,
            "message_count": len(st.session_state.chat_history),
            "created_at": datetime.now().isoformat(),
            "messages": [
                {
                    "role": msg["role"],
                    "content": msg["content"],
                    "timestamp": msg["timestamp"].isoformat(),
                    "metadata": msg.get("metadata", {})
                }
                for msg in st.session_state.chat_history
            ]
        }
        
        st.download_button(
            label="ğŸ’¾ JSON ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=json.dumps(chat_export, ensure_ascii=False, indent=2),
            file_name=f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
    
    st.markdown("---")
    
    # ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
    st.subheader("ğŸ§­ ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")
    
    if st.button("ğŸ  ãƒ›ãƒ¼ãƒ ã«æˆ»ã‚‹", use_container_width=True):
        st.switch_page("app.py")
    
    if st.button("ğŸ”„ ãƒ•ãƒ­ãƒ¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", use_container_width=True):
        st.switch_page("pages/project_management.py")
    
    if st.button("ğŸ¤– AIè¨­å®š", use_container_width=True):
        st.switch_page("pages/ai_settings.py")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.caption("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: å…·ä½“çš„ãªè³ªå•ã»ã©æœ‰ç”¨ãªå›ç­”ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé¸æŠã«ã‚ˆã‚Šæ›´ã«ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™ã€‚")